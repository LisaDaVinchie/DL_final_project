Elapsed time [s]:
6858.143424510956

Train losses
0.06605252885964683	0.0596317717132696	0.054931831834575694	0.046298741610320646	0.03897767142101538	0.036094052546824844	0.03310127341384062	0.029977162818313398	0.02683729225334636	0.024273156857211247	0.022754077030397363	0.02173981628716076	0.020817982229641263	0.020258666881125237	0.01955997518982886	0.018949674847021397	0.018425448444207244	0.017871444918195607	0.01736948964555092	0.016919694300049744	0.016373371329980457	0.01579342704639045	0.015535830331527896	0.015304694400440225	0.01481690476764895	0.01460412016395521	0.01426962133113432	0.013887760447620141	0.013635329639049225	0.013379612351846945	0.013186439306516962	0.012732644419830425	0.012569878813561771	0.012371960346099732	0.01216223955929998	0.011982498633937612	0.011813940621002852	0.011469792625116316	0.011389676590305622	0.011318186622967848	0.011150130665292858	0.010938216592184547	0.010761806245709167	0.01087782109036866	0.010628548650624514	0.01053558088150124	0.010702810168930535	0.010491939486260198	0.010502590704336274	0.010445343079399951	0.010342704393669994	0.010282937292455201	0.010292946451368844	0.010053285698000233	0.010091769420124413	0.010177152133059508	0.010075070480452657	0.009979069612052293	0.009977741196871061	0.009920314849845834	0.009904159058512645	0.009831334950492543	0.009730103103246597	0.009851639551503439	0.009677512413072104	0.00980343411211876	0.009708980201517154	0.009650234278454928	0.00967125797262497	0.009661028391886302	0.009613441020342688	0.009692600045460015	0.009704378608770665	0.009604579252235637	0.009565349516740871	0.009582807043999325	0.00955014438170349	0.00949610036154974	0.009735474563904351	0.009461021225772536	

Test losses
0.0617286734282646	0.0574131242786764	0.0510485661079694	0.03894502318596622	0.03605863145418736	0.03310243599489541	0.029686708114334562	0.026183625860375766	0.02351992959559046	0.02180460123781211	0.02052499397308435	0.019623722506409078	0.01898811111768954	0.018309202026144236	0.017656034946107627	0.01760161576603054	0.01681258811232368	0.01645618822854236	0.015858163448227745	0.015040797582753446	0.014687039411049152	0.014307446356575309	0.014743832039975039	0.014396327989515298	0.013526969229743663	0.013576621645204881	0.01296274173342912	0.012815257160994386	0.012737784001499556	0.012630172329621906	0.01206761303433177	0.012268205862079919	0.011916104184327906	0.011831342924181016	0.011420012635258598	0.01113887333388394	0.01125333212799766	0.010745822812439363	0.010726006971513227	0.010363979092117597	0.010603837539871423	0.010305742657775657	0.010176367860382701	0.01028878260533806	0.01014527241318624	0.010266505494589651	0.010086170867792305	0.01030054314809771	0.009827889730203859	0.009966469525370312	0.01005272951970226	0.009678387416102148	0.010091706790456664	0.009794605611293082	0.009739393041384728	0.009498669990363367	0.009708844153817129	0.009705086938778426	0.009784150269320708	0.009752023619960628	0.009654526121134039	0.009248506590316919	0.009546621213788905	0.00946265982487901	0.009384767277387546	0.009484615006441748	0.00936372976225869	0.009614843234197729	0.009239970162709011	0.009579678940865416	0.009136503329076697	0.009442865210664996	0.009401412981076275	0.00923351409186034	0.009144789851411995	0.009342308975490817	0.009227085190487965	0.009607536971988925	0.009133657567021516	0.009166731651334688	

Train dice coefficient
0.5403984565007287	0.5563535707339935	0.5684165894896925	0.6004690775368682	0.6221596327233716	0.6245682893102932	0.6276702201701402	0.6296738517247257	0.6328700546892206	0.6342788023506404	0.6339670197737588	0.6331383991590416	0.6343655224480824	0.6345057013379819	0.6341783223673494	0.6351827148498179	0.6346324140254959	0.6359557336619704	0.635135484835183	0.6359449942317076	0.635397332066558	0.636850399228662	0.6354055819901268	0.6373372191638882	0.6358765551979274	0.6370429632043242	0.6355812380801129	0.6385625367874737	0.6378549072052028	0.6385051231728013	0.6371918341832795	0.6387039144298109	0.6389698797024248	0.6388297890544967	0.6392317405569807	0.6387330326905701	0.6412022253802956	0.6404980501493905	0.640069864161793	0.6400713949640159	0.6411205562568153	0.6413437508248984	0.6432626806984549	0.6423989154972961	0.6415161496463027	0.6419285039774639	0.6415842922449363	0.6435962031761553	0.6423138390208741	0.6411442663618484	0.6410517004564087	0.6418446633836304	0.6404708478779206	0.6431160419917482	0.64281484417589	0.6432151042426736	0.6435360964759879	0.6425534811240812	0.6432488311283603	0.6438245248335784	0.6422563994821394	0.6431458752053538	0.642560860247725	0.6426169386031214	0.6438050596886165	0.642476780135031	0.6425337679788888	0.6434275565382636	0.6436117097678741	0.6433142423803677	0.6431133884692873	0.6437226948682786	0.6433262753189897	0.6434591350804619	0.6432106999112918	0.6429940003138076	0.6444206797801039	0.6430982466960261	0.6433375727081805	0.6425441763506311	

Test dice coefficient
0.5557377175785545	0.5695442045213203	0.5855747861674144	0.6203984756553974	0.6417538641822187	0.6329559926991857	0.6345448425155655	0.6370571776126723	0.647362205028782	0.6405558352579181	0.6407062739549435	0.6458264803276373	0.6429877382896486	0.6428830264410369	0.6408719946250385	0.6455911215622342	0.644518341221671	0.6373309023076446	0.6433094548324265	0.6447209923629266	0.6460886365064118	0.6428875875071582	0.6416964633513729	0.640759868190005	0.6459454057481188	0.6506987905492642	0.6402535565858211	0.6465220181515741	0.6468439525155161	0.6421570573852696	0.6457774661098131	0.6410263055430543	0.6474358808599734	0.6477391958180094	0.6469013139801393	0.6458735375531457	0.6419213580764618	0.649348502431429	0.6533390618361538	0.6485925377613027	0.6459281342288051	0.6475106747213981	0.6451883188989944	0.6482904021709825	0.6506588466855947	0.6522486840991691	0.6500687636353295	0.6472460112988249	0.6490135054168119	0.6485218619756337	0.6533248231639739	0.6510999548436003	0.6449184634108784	0.6501402944350566	0.6450135907705429	0.6520953919383693	0.6528927098285611	0.6521872650353794	0.6518665211546985	0.6465213145356868	0.6519073836910176	0.6523000568677882	0.6521790901781476	0.6488448433277048	0.6532539267003431	0.6507640026317733	0.6481843323463803	0.6514237550955888	0.6489274668396752	0.6490504156055557	0.6488907410954297	0.6536924108651788	0.6505905961635359	0.6496248279060527	0.6505769960241674	0.6502492366048185	0.6458481386283784	0.6496865877857391	0.6555482270418389	0.6534282213502328	

Learning rate
0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	0.0001	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	2.5e-05	1.25e-05	

Parameters
    "training": {
        "n_train": -1,
        "n_test": -1,
        "classes": [],
        "batch_size": 32,
        "epochs": 80,
        "learning_rate": 0.0002,
        "loss_kind": "mse",
        "_possible_loss_kinds": [
            "mse",
            "l1"
        ],
        "optimizer": "Adam",
        "model_name": "unet_lite",
        "lr_scheduler": "lambda",
        "_possible_lr_schedulers": [
            "none",
            "step",
            "lambda"
        ],
        "_possible_model_names": [
            "unet",
            "unet_lite",
            "dummy",
            "simple"
        ],
        "dataset_idx": 1,
        "mask_idx": 1
    },
    "masks": {
        "n_masks": 1000,
        "mask_kind": "lines",
        "_possible_mask_kinds": [
            "square",
            "lines"
        ],
        "square": {
            "mask_percentage": 0.1
        },
        "lines": {
            "num_lines": 5,
            "min_thickness": 1,
            "max_thickness": 3
        }
    },
    "dataset": {
        "nrows": 32,
        "ncols": 32
    },
    "lr_schedulers": {
        "step": {
            "step_size": 4,
            "gamma": 0.1
        },
        "lambda": {
            "factor": 0.5,
            "step_size": 20
        }
    },
    "model": {
        "unet": {
            "e_filters": [
                3,
                64,
                128,
                256,
                512,
                512,
                512,
                512,
                512
            ],
            "d_filters": [
                512,
                512,
                512,
                512,
                256,
                128,
                64,
                3,
                3
            ],
            "e_kernels": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ],
            "d_kernels": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1
            ],
            "e_bn": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ],
            "d_bn": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0
            ],
            "e_strides": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ],
            "d_strides": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "unet_lite": {
            "e_filters": [
                3,
                32,
                32,
                64,
                64,
                128,
                128,
                256,
                256
            ],
            "d_filters": [
                256,
                128,
                128,
                64,
                64,
                32,
                32,
                3,
                3
            ],
            "e_kernels": [
                7,
                5,
                5,
                3,
                3,
                3,
                3,
                3
            ],
            "d_kernels": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1
            ],
            "e_bn": [
                0,
                1,
                0,
                1,
                0,
                1,
                0,
                1
            ],
            "e_strides": [
                1,
                2,
                1,
                2,
                1,
                2,
                1,
                2
            ]
        }
    }



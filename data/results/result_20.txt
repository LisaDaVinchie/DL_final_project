Elapsed time [s]:
184.11357402801514

Train losses
0.25046340055054417	0.2514204724501133	0.252410149986815	0.25019558319489066	0.2529886428145226	0.2513983260017649	0.25243703307301174	0.25199021515722936	0.25311131015805816	0.25115822684673844	0.252116508470795	0.2527732599803031	0.25134254854397997	0.251233521880994	0.25204271410667684	0.2515002152771304	0.2526007745361348	0.2517790132096195	0.2530248934668947	0.2524622402753754	0.25363195380250014	0.2519518974475758	0.2526898348927814	0.2532198851400204	0.25159938950109034	0.2524166978758962	0.25230971400526087	0.2521620099389563	0.2525353907525709	0.2505178575364134	0.252966577786303	0.25244273354159913	0.2526566407371282	0.25205395095210525	0.2515591164310553	0.2519539183022918	0.2528985490503321	0.25206777144106635	0.2521701593681622	0.2525748941648161	0.2522169299932509	0.252033245081933	0.252328845473294	0.2517112200709055	0.2522941078303731	0.2526866399274188	0.25215756344658613	0.2522915051464575	0.251565590698787	0.25208726905057616	0.2510199381134101	0.2498234473213092	0.2524146828455719	0.25172502335013863	0.2506070692936951	0.2522535949071698	0.2527786576725279	0.2516670258078577	0.2514433467783033	0.2526803104590276	0.2525270676913302	0.2515237155438731	0.2528795362121738	0.25141231325154195	0.25302326609267445	0.2529632043614625	0.2521818249168065	0.2517777733862727	0.25181084422508093	0.2515947746291723	0.2508152179780821	0.25080859661235716	0.2519463491701255	0.2516311209332234	0.25096452739385555	0.25282028419011704	0.25163749107102684	0.2526847146408886	0.2525047589362764	0.2520687237580307	

Test losses
0.24388656899379255	0.24737854306730886	0.24792680130889913	0.24841272666944664	0.2474002792197219	0.24763227955163417	0.24704434592675115	0.24773366905500976	0.24619872095767842	0.24512472009883335	0.2432874880454313	0.2473679917376018	0.2461739646003584	0.24461567474481496	0.2501065707286748	0.24701325447704583	0.2479646114246768	0.24442368237734133	0.24852312170220547	0.24756174570071093	0.248848836107798	0.24586675244543135	0.2456713194404008	0.25039595561733974	0.24473011171118128	0.24645948184625027	0.24438172757779766	0.2447030102546004	0.2484470679753159	0.24635128977675694	0.24442417895491086	0.24746789234447938	0.24834850284535084	0.246274284540657	0.24579988450453877	0.24830260033238036	0.24750711356683516	0.24461258135578207	0.24691167427902527	0.24757456682105128	0.2468504130590103	0.2472113505253136	0.24708609445634105	0.24579644322722471	0.24723117892527494	0.24642273332289727	0.24659956441137004	0.2496756167244476	0.2449934828716914	0.24563295544012462	0.24800004647665808	0.24480254709929664	0.24908910077704668	0.24670449238233005	0.24807182644569983	0.24838350591893005	0.2460401624048092	0.24454219858560222	0.24484761281522724	0.24658004271998243	0.24275862157197242	0.24525110480416804	0.2470219657170656	0.24838074131877041	0.24365434850986692	0.2456826492301191	0.24819298589123207	0.2453637554784571	0.24633252636419672	0.24759347347202687	0.2446978137896386	0.24457078278806219	0.24858550849713537	0.24707682637778824	0.2460926069645669	0.2465916948518909	0.24389250792746675	0.2489272745347189	0.2486867786756736	0.244300444962778	

Train dice coefficient
0.1522997589610404	0.15191886335333535	0.147925891024484	0.15237074350703583	0.14930693775660026	0.14972416734349933	0.14785981580254193	0.15296322520597172	0.15121410860624687	0.15026784350327002	0.15180144673780677	0.15296211473053808	0.1507245129255292	0.15047555561704373	0.15265161565439705	0.1528963185756118	0.14822806338727962	0.14857657437634592	0.15049706025646148	0.1520672852042136	0.14879329296064125	0.15128761923956638	0.15074808275583867	0.14895279990201393	0.14914177294816724	0.15010715614109485	0.14936086700194295	0.14821374138115012	0.15178611171140474	0.15328865263626193	0.14862332265083145	0.149529568134846	0.14960347582452166	0.14920414553319258	0.15000487430170364	0.15263039294217798	0.15179411488169245	0.15001183075385985	0.15093170859369787	0.14957192153685148	0.15013161781205184	0.15487965082311844	0.14888929349283017	0.14948011472779638	0.1510482776489455	0.14677726532101426	0.14869331839481797	0.15354454648448096	0.14857419416588677	0.15121506724693348	0.15141497875410923	0.15245827532594042	0.14929420827496764	0.14798554811435366	0.1492694298071234	0.15281644368669337	0.1519425294796007	0.15293877403402506	0.150656608267767	0.15158102268105303	0.14723235339125426	0.15183802116979747	0.14737653613412569	0.14703763873214679	0.1483935191346515	0.14663194954807063	0.14834440166402962	0.15310092139337386	0.15118032941109658	0.1553582853824575	0.15235989484969162	0.14866585881591568	0.15165239744174627	0.14990638545953486	0.15304441044539638	0.1526572586074549	0.15150066847721824	0.15265832348359412	0.15175963626732542	0.14447288488073498	

Test dice coefficient
0.17371455171793676	0.17203189153306872	0.16984191611470628	0.1704798725741909	0.17385057091328562	0.1700180765357357	0.17141902360783387	0.16867312907793952	0.1675454421158898	0.16951267346343707	0.16948250321592762	0.17366860475279003	0.17206945103978288	0.17419009872025085	0.17297350169644615	0.1666345309875125	0.1704858995566902	0.16977059434937078	0.17082570272306574	0.1677279911502871	0.1721374672691284	0.17189391821302435	0.17394046107731678	0.16799529844731914	0.17368885958757532	0.17494732926249681	0.17099237311384863	0.1705868969406185	0.16986331090803722	0.16819355766456354	0.17029204703732398	0.17238196972487752	0.16757799216018987	0.17059051423072621	0.1726237398347108	0.1690002747745227	0.16554538218836376	0.16543822787356152	0.17137754222415202	0.17124261540068408	0.16978544998699577	0.1704240080624814	0.17314570887989036	0.17406479453500223	0.17020349007950272	0.16843897846505895	0.1713871611797058	0.16639194669210655	0.16750730260892077	0.1701244622172513	0.17033248731572845	0.1737625029870411	0.16676338244512098	0.17557321709690268	0.16893365940227395	0.1698303317017921	0.17074391888832124	0.17131962978124082	0.1712858286813723	0.16640630283121177	0.17297313771454387	0.17070220541612358	0.16969255788971704	0.1733879992589402	0.17198755436994648	0.1685463803717079	0.1698874268753043	0.17188832403271317	0.17025405548179068	0.1709748685881821	0.17183485076078686	0.16815084879798756	0.16804292248295757	0.17028314049982524	0.1687386131269751	0.1698221763339852	0.17504190741979544	0.17032574832943528	0.16411932301640209	0.17109984980812495	

Learning rate
0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	0.0002	2e-05	2e-05	2e-05	2e-05	2e-05	2e-05	2e-05	2e-05	2e-05	2e-05	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000003e-06	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-07	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000004e-08	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000005e-09	2.0000000000000008e-10	2.0000000000000008e-10	2.0000000000000008e-10	2.0000000000000008e-10	2.0000000000000008e-10	2.0000000000000008e-10	2.0000000000000008e-10	2.0000000000000008e-10	2.0000000000000008e-10	2.0000000000000008e-10	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-11	2.000000000000001e-12	

Parameters
    "training": {
        "n_train": -1,
        "n_test": -1,
        "classes": [],
        "batch_size": 32,
        "epochs": 80,
        "learning_rate": 0.0002,
        "loss_kind": "mse",
        "_possible_loss_kinds": [
            "mse",
            "l1"
        ],
        "optimizer": "Adam",
        "model_name": "dummy",
        "lr_scheduler": "lambda",
        "_possible_lr_schedulers": [
            "none",
            "step",
            "lambda"
        ],
        "_possible_model_names": [
            "unet",
            "unet_lite",
            "dummy",
            "simple"
        ],
        "dataset_idx": 1,
        "mask_idx": 1
    },
    "masks": {
        "n_masks": 1000,
        "mask_kind": "lines",
        "_possible_mask_kinds": [
            "square",
            "lines"
        ],
        "square": {
            "mask_percentage": 0.1
        },
        "lines": {
            "num_lines": 5,
            "min_thickness": 1,
            "max_thickness": 3
        }
    },
    "dataset": {
        "nrows": 32,
        "ncols": 32
    },
    "lr_schedulers": {
        "step": {
            "step_size": 4,
            "gamma": 0.1
        },
        "lambda": {
            "factor": 0.1,
            "step_size": 10
        }
    },
    "model": {
        "unet": {
            "e_filters": [
                3,
                64,
                128,
                256,
                512,
                512,
                512,
                512,
                512
            ],
            "d_filters": [
                512,
                512,
                512,
                512,
                256,
                128,
                64,
                3,
                3
            ],
            "e_kernels": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ],
            "d_kernels": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1
            ],
            "e_bn": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ],
            "d_bn": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0
            ],
            "e_strides": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ],
            "d_strides": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "unet_lite": {
            "e_filters": [
                3,
                32,
                32,
                64,
                64,
                128,
                128,
                256,
                256
            ],
            "d_filters": [
                256,
                128,
                128,
                64,
                64,
                32,
                32,
                3,
                3
            ],
            "e_kernels": [
                7,
                5,
                5,
                3,
                3,
                3,
                3,
                3
            ],
            "d_kernels": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1
            ],
            "e_bn": [
                0,
                1,
                0,
                1,
                0,
                1,
                0,
                1
            ],
            "e_strides": [
                1,
                2,
                1,
                2,
                1,
                2,
                1,
                2
            ]
        }
    }


